import torch
import torch.nn as nn
#from .modules import VGG_FeatureExtractor, BidirectionalLSTM
#from .modules import TPS, ResNet_FeatureExtractor, BidirectionalLSTM, Attention

import sys
sys.path.append(r"C:\Users\TAMSystech\anaconda3\envs\ocr2\Lib\site-packages\easyocr\model\modules")

from modules import TPS, ResNet_FeatureExtractor, BidirectionalLSTM, Attention


class Model(nn.Module):
    print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!모델에 내가 만든 모델.py 들어옴 num_class nn.Module: {nn.Module}')

    def __init__(self, num_fiducial, input_channel, output_channel, hidden_size, num_class, use_cuda=False):
        print(
            f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init num_fiducial : {num_fiducial}')
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init input_channel : {input_channel}')
        print(
            f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init output_channel : {output_channel}')
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init hidden_size : {hidden_size}')
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init num_class : {num_class}')
        print(
            f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init use_cuda : {use_cuda}')

        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init Model : {Model}')
        # print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!None_VGG_BiLSTM_CTC 내가 만든 모델 Model init self : {self}')
        # print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!내가 만든 모델 Model init self : {self}')
        super(Model, self).__init__()
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init 에러나기전?????  self : {self}')
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init 에러나기전?????  Model : {Model}')

        # TPS module
        self.TPS = TPS()

        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init 에러나기전?????  self.TPS : {self.TPS}')
        

        # FeatureExtraction module (you can replace this with ResNet or any other feature extractor)
        self.FeatureExtraction = ResNet_FeatureExtractor(input_channel, output_channel)

        print(
            f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init 에러나기전?????  self.FeatureExtraction : {self.FeatureExtraction}')
        
        self.AdaptiveAvgPool = nn.AdaptiveAvgPool2d((None, 1))

        print(
            f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init 에러나기전?????  self.AdaptiveAvgPool : {self.AdaptiveAvgPool}')
        

        # SequenceModeling module (BiLSTM)
        self.SequenceModeling = nn.Sequential(
            BidirectionalLSTM(output_channel, hidden_size, hidden_size),
            BidirectionalLSTM(hidden_size, hidden_size, hidden_size)
        )

        print(
            f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init 에러나기전?????  self.SequenceModeling : {self.SequenceModeling}')


        self.SequenceModeling_output = hidden_size

        print(
            f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init 에러나기전?????  self.SequenceModeling_output : {self.SequenceModeling_output}')


        # Attention module
        self.Attention = Attention(hidden_size, num_class)
        print(
            f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!TPS_ResNet_BiLSTM_Attn2 내가 만든 모델 Model init 에러나기전?????  self.Attention : {self.Attention}')


    # def forward(self, x):
    def forward(self, input, text):
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!내가 만든 모델 클래스 TPS_ResNet_BiLSTM_Attn2 forward 함수 들어옴 self : {self}')
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!내가 만든 모델 클래스 TPS_ResNet_BiLSTM_Attn2 forward 함수 들어옴 x : {input}')

        # TPS transformation
        input = self.TPS(input)

        # Feature extraction
        visual_feature = self.FeatureExtraction(input)
        visual_feature = self.AdaptiveAvgPool(visual_feature.permute(0, 3, 1, 2))
        visual_feature = visual_feature.squeeze(3)
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!내가 만든 모델 클래스 TPS_ResNet_BiLSTM_Attn2 forward 함수 들어옴 Feature extraction 후 visual_feature : {visual_feature}')
        

        # Sequence modeling
        contextual_feature = self.SequenceModeling(visual_feature)

        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!내가 만든 모델 클래스 TPS_ResNet_BiLSTM_Attn2 forward 함수 들어옴 Sequence modeling 후 contextual_feature : {contextual_feature}')

        # Attention
        prediction = self.Attention(contextual_feature)
        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!내가 만든 모델 클래스 TPS_ResNet_BiLSTM_Attn2 forward 함수 들어옴 Attention 후 prediction : {prediction}')
        
        return prediction

# 모델 인스턴스 생성
model = Model(num_fiducial=20, input_channel=1, output_channel=512, hidden_size=256, num_class=10, use_cuda=False)

print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!모델 인스턴스 생성 TPS_ResNet_BiLSTM_Attn2 model : {model}')


# 더미 데이터 생성
dummy_input = torch.randn(1, 1, 32, 100)

# 순전파 수행
output = model(dummy_input)
print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!모델 인스턴스 생성 TPS_ResNet_BiLSTM_Attn2 output : {output}')


# # 모델 인스턴스 생성
# model = Model(input_channel=1, output_channel=1, hidden_size=46, num_class=1536)
#
# # 더미 데이터 생성
# dummy_input = torch.randn(1, 1, 102, 204)
#
# # 순전파 수행
# output = model(dummy_input)
#
# # 각 레이어에서의 출력 크기 확인
# print(f"Output size after FeatureExtraction: {output.size()}")
#
# # FeatureExtraction 이후의 출력 크기 확인
# print(f"Size after FeatureExtraction: {model.FeatureExtraction(dummy_input).size()}")
#
# # SequenceModeling 이후의 출력 크기 확인
# print(f"Size after SequenceModeling: {model.SequenceModeling(model.FeatureExtraction(dummy_input)).size()}")